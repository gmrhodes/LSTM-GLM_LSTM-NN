# This file fits the LSTM-NN for each simulation and outputs the predicted MRLs. 
#################################################### USER SET-UP ####################################################
#Survival model ("aft" or "cox")
surv_model = "aft"

#Prediction time 
t = 5

#Number of iterations
iters = 500

#Number of cores to parallelize across
num_cpu = 25

#Directory path of folder containing context vector data sets generated by 02_create_contextVecs.py
##Must contain sub-directories "aft" and "cox"
contextVec_path = "D:/Simulations/context_vectors/"

#Directory path of folder containing train/test data sets generated by 05_trainTest_ipcw.R
##Must contain sub-directories "aft" and "cox"
ipcw_path = "D:/Simulations/ipcw/"

#Directory path of output folder to write results to
##Must contain sub-directories "aft" and "cox"
output_path = "D:/Simulations/lstmNN/"


#################################################### SET-UP ####################################################
seed_number=5678
import os
os.environ['PYTHONHASHSEED']='0'
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'
import random
random.seed(seed_number)
import numpy as np
np.random.seed(seed_number)
import tensorflow as tf
import tensorflow.keras.backend as K
from tensorflow.keras import layers as tfkl
tf.random.set_seed(seed_number)
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)
tf.compat.v1.disable_eager_execution()
import pandas as pd
import multiprocessing as mp

#LSTM-NN Hyperparameters
epoch = 5000 #training epochs
units = 3 #dimension of weight matrices
lamb = 0 #L-2 penalty tuning parameter


#################################################### FUNCTIONS TO CONSTRUCT LSTM-NN #################################################### 
#Function to compute & return loss 
def loss_wrapper(ipcw):
    def loss(y_true, y_pred):
        return K.sum(ipcw*K.square(y_true - y_pred)) / K.sum(ipcw)
    return loss

#Function to build LSTM-NN
def lstmNN_build(num_cov):
    input_list = []
    
    #Input IPCWs for loss function
    ipcw = tfkl.Input(shape=(1,), name="ipcw")
    input_list.append(ipcw)
    
    #Input covariates for predicting MRL
    covar_input = tfkl.Input(shape=(num_cov,), name="covariates")
    input_list.append(covar_input)
    
    #Predict MRL using feed-forward layers
    dense1 = tfkl.Dense(units, kernel_initializer=tf.keras.initializers.glorot_uniform(), activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(lamb), name="dense1")(covar_input)
    dense2 = tfkl.Dense(units, kernel_initializer=tf.keras.initializers.glorot_uniform(), activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(lamb), name="dense2")(dense1)
    output = tfkl.Dense(1, name="output")(dense2)     
        
    #Compile & return model
    mrlNN = tf.keras.models.Model(inputs=input_list, outputs=output)
    mrlNN.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=loss_wrapper(ipcw))
    return mrlNN


#################################################### FUNCTION TO FIT LSTM-NN & OUTPUT MRL PREDICTIONS #################################################### 
#Function to fit LSTM-NN for simulation i and output MRL predictions
def iter_fn(i):   
    random.seed(seed_number)
    np.random.seed(seed_number)
    tf.random.set_seed(seed_number)
    
    #Read in & prepare context vector data 
    contVecDF = pd.read_csv("{}{}/contextVec{}.csv".format(contextVec_path, surv_model, i))
    contVecDF = contVecDF.loc[:, (contVecDF!=0).any(axis=0)]
    contVecDF['log_RRL'] = np.log(contVecDF['restricted_residual_life']) 
    
    #Read in training & testing IDs & IPCWs
    idTrain = pd.read_csv("{}{}/trainID{}.csv".format(ipcw_path, surv_model, i))
    idTest = pd.read_csv("{}{}/testID{}.csv".format(ipcw_path, surv_model, i))
    
    #Separate data set into training and testing, and merge IPCWs
    cvTrain = contVecDF.merge(idTrain, how="right", on="id", copy=True)
    cvTest = contVecDF.merge(idTest, how="right", on="id", copy=True)
            
    #Extract covariates, repsonse, and IPCWs from data sets
    ##Training dataset 
    trainCov = cvTrain.loc[:,np.logical_or(cvTrain.columns.str.startswith('long_cov'), cvTrain.columns=='base_cov')].values
    trainResp = cvTrain.log_RRL.values.reshape((-1,1))    
    trainIPCW = cvTrain.ipcw.values.reshape((-1,1))
    input_train = [trainIPCW, trainCov]    
    ##Testing dataset
    testCov = cvTest.loc[:,np.logical_or(cvTest.columns.str.startswith('long_cov'), cvTest.columns=='base_cov')].values   
    testIPCW = cvTest.ipcw.values.reshape((-1,1))
    input_test = [testIPCW, testCov]
        
    #Set-up tensorflow session
    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)
    sess = tf.compat.v1.Session(config=session_conf)
    tf.compat.v1.keras.backend.set_session(sess)     
    
    #Fit LSTM-NN on training data          
    lstmNN = lstmNN_build(trainCov.shape[1])       
    lstmNN.fit(x=input_train, y=trainResp, epochs=epoch, batch_size=128, verbose=0)  
    
    #Compute & write training MRL predictions
    trainPred = lstmNN.predict(input_train)    
    trainPredDF = pd.DataFrame(data=np.concatenate((cvTrain.loc[:,('id','restricted_residual_life','delta_star','ipcw')].values, trainPred), axis=1), 
                               columns=['id','restricted_residual_life','delta_star','ipcw','pred']) 
    trainPredDF.to_csv("{}{}/trainPred{}.csv".format(output_path, surv_model, i), index=False)
    
    #Compute & write testing MRL predictions 
    testPred = lstmNN.predict(input_test)
    testPredDF = pd.DataFrame(data=np.concatenate((cvTest.loc[:,('id','restricted_residual_life','delta_star','ipcw')].values, testPred), axis=1), 
                              columns=['id','restricted_residual_life','delta_star','ipcw','pred']) 
    testPredDF.to_csv("{}{}/testPred{}.csv".format(output_path, surv_model, i), index=False)
    
    #Reset session & seeds
    del lstmNN
    tf.compat.v1.keras.backend.clear_session()
    tf.compat.v1.reset_default_graph()  
    random.seed(seed_number)
    np.random.seed(seed_number)
    tf.random.set_seed(seed_number)      
    
    
#################################################### MAIN ####################################################
if __name__ == '__main__':
    #Fit LSTM-NN for each simulation & write MRL predictions to file
    pool = mp.Pool(num_cpu)
    pool.map(iter_fn, np.arange(1,(iters+1)))      
    pool.close()
    pool.join()  
    
        

        
        
    
    



   









