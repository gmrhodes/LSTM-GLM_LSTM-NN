# This file divides the patients in each simulation into a training & testing data sets
# and computes inverse probability of censoring weights (IPCWs).
# The file outputs a training data set & testing data set of patient IDs and IPCWs for each simulation.
library(dplyr)
library(splitstackshape)
library(data.table)
library(survival)
library(foreach)
library(doParallel)
set.seed(5678)


############################### USER SET-UP ##############################
#Survival model ("aft" or "cox")
surv_model = "aft"

#Prediction time
t = 5

#Number of iterations
iter = 500

#Number of cores to parallelize across
numCores = 25

#Proportion of data in training data set
trainProp = 0.5

#Directory path of folder containing data generated by 01_generate_data.R
##Must contain sub-directories "aft" and "cox"
input_path = "D:/Simulations/data/"

#Directory path of output folder to write results to
##Must contain sub-directories "aft" and "cox"
output_path = "D:/Simulations/ipcw/"


##########################  FUNCTION TO CALCUATE IPCW ########################## 
#Data set of analysis variables: df
#Prediction time: t
ipcw_computation = function(df, t){
  #Create indicators
  present_ind = as.integer(df$Y > t)
  censored_ind = 1 - df$delta
  
  #Estimate survival function of censoring time via Kaplan-Meier
  kmf = survfit(Surv(df$U, censored_ind) ~ 1)
  kmf.summ = summary(kmf, times=df$Y)
  kmf_df = data.frame(days=kmf.summ[[2]], prob=kmf.summ[[6]])
  kmf_df = kmf_df[match(df$Y, kmf_df$days),]
  
  #Create weights
  ipcw = (df$delta_star * present_ind) / kmf_df$prob
  ipcw = ifelse(df$delta_star==0, 0, ipcw)
  return(ipcw)
}


##########################  FUNCTION TO CREATE TRAIN/TEST DATA SETS & COMPUTE IPCWS FOR GIVEN ITERATION ########################## 
#Survival time data set: timeDF
iterFN = function(timeDF) {
  library(splitstackshape)
  library(data.table)
  library(survival)
  set.seed(5678)
  
  #Create data set of patient IDs and response variables for patients at risk at t
  respDF_t = timeDF[which(timeDF$Y>t), c("id","U","delta","Y","delta_star")]
  
  #Divide patients into training & testing data sets, stratifying on censoring status
  strat_sample = stratified(data.table(id=respDF_t$id, delta_star=respDF_t$delta_star),
                            group="delta_star", size=trainProp, replace=F, bothSets=T)
  trainDF = respDF_t[which(respDF_t$id %in% strat_sample[[1]]$id),]
  testDF = respDF_t[which(respDF_t$id %in% strat_sample[[2]]$id),]
  
  #Compute IPCWs
  ipcw_train = ipcw_computation(trainDF, t)
  ipcw_test = ipcw_computation(testDF, t)
  
  #Output training & testing data sets of IDs and IPCWs
  trainOut = data.frame(id=trainDF$id, ipcw=ipcw_train)
  testOut = data.frame(id=testDF$id, ipcw=ipcw_test)
  
  return(list(trainOut, testOut))
}


############################### MAIN ##############################
#Input survival time data for each simulation
time_list = vector(mode="list", length=iter)
for(i in 1:iter) {
  time_list[[i]] = read.table(paste0(input_path, surv_model, "/survTimes", i, ".csv"), sep=",", header=T)
}

#Set up parallelization
myCluster = makeCluster(numCores, type="PSOCK") 
registerDoParallel(myCluster)

#Create train/test data set & compute IPCWs for each simulation
results = foreach(i=1:iter) %dopar% {iterFN(time_list[[i]])}
stopCluster(myCluster)

#Write data sets for each simulation
for(i in 1:iter) {
  write.table(results[[i]][[1]], paste0(output_path, surv_model, "/trainID",i,".csv"), sep=",", row.names=F)
  write.table(results[[i]][[2]], paste0(output_path, surv_model, "/testID",i,".csv"), sep=",", row.names=F)
}

